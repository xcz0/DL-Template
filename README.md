# æ·±åº¦å­¦ä¹ é¡¹ç›®æ¨¡æ¿

åŸºäº PyTorch Lightning + Hydra çš„æ·±åº¦å­¦ä¹ é¡¹ç›®æ¨¡æ¿ï¼Œæ”¯æŒçµæ´»çš„é…ç½®ç®¡ç†å’Œå®éªŒè·Ÿè¸ªã€‚

## ç‰¹æ€§

- ğŸ”§ **Hydra é…ç½®ç®¡ç†** - æ¨¡å—åŒ–é…ç½®ï¼Œå‘½ä»¤è¡Œè¦†ç›–ï¼Œå¤šè¿è¡Œæ”¯æŒ
- âš¡ **PyTorch Lightning** - ç®€åŒ–è®­ç»ƒå¾ªç¯ï¼Œè‡ªåŠ¨æ··åˆç²¾åº¦ï¼Œå¤š GPU æ”¯æŒ
- ğŸ“Š **å®éªŒè·Ÿè¸ª** - TensorBoardã€WandBã€CSV æ—¥å¿—
- ğŸ” **è¶…å‚æ•°æœç´¢** - Optuna é›†æˆ
- ğŸ“¦ **DVC æ•°æ®ç®¡ç†** - æ•°æ®ç‰ˆæœ¬æ§åˆ¶
- ğŸ› ï¸ **å¼€å‘å·¥å…·** - Ruff ä»£ç æ£€æŸ¥ï¼ŒMake å‘½ä»¤

> è¯´æ˜ï¼šMNIST æ¨¡å‹ç°å·²æ”¯æŒ `test` æµç¨‹ï¼ˆ`test/loss`ã€`test/acc` æŒ‡æ ‡ï¼‰ã€‚

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ configs/                 # Hydra é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ _base.yaml          # åŸºç¡€é…ç½® (paths, hydra, callbacks, logger, trainer)
â”‚   â”œâ”€â”€ train.yaml          # è®­ç»ƒå…¥å£é…ç½®
â”‚   â”œâ”€â”€ eval.yaml           # è¯„ä¼°å…¥å£é…ç½®
â”‚   â”œâ”€â”€ predict.yaml        # é¢„æµ‹å…¥å£é…ç½®
â”‚   â”œâ”€â”€ debug.yaml          # è°ƒè¯•å…¥å£é…ç½®
â”‚   â”œâ”€â”€ data/               # æ•°æ®é›†é…ç½® (cifar10, mnist)
â”‚   â”œâ”€â”€ debug/              # è°ƒè¯•é…ç½® (default, limit, profiler)
â”‚   â”œâ”€â”€ experiment/         # å®éªŒé…ç½®
â”‚   â”œâ”€â”€ hparams_search/     # è¶…å‚æœç´¢é…ç½® (optuna)
â”‚   â””â”€â”€ model/              # æ¨¡å‹é…ç½®
â”œâ”€â”€ src/                     # æºä»£ç 
â”‚   â”œâ”€â”€ train.py            # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ eval.py             # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ predict.py          # é¢„æµ‹è„šæœ¬
â”‚   â”œâ”€â”€ data/               # æ•°æ®æ¨¡å—
â”‚   â”œâ”€â”€ models/             # æ¨¡å‹å®šä¹‰
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”œâ”€â”€ logs/                    # æ—¥å¿—ç›®å½•
â””â”€â”€ saved_models/            # ä¿å­˜çš„æ¨¡å‹
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
make install
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
# é»˜è®¤è®­ç»ƒ (CIFAR-10 + ResNet)
make train

# ä½¿ç”¨ç‰¹å®šå®éªŒé…ç½®
make train-exp EXP=cifar_densenet

# æˆ–ç›´æ¥ä½¿ç”¨ Python
uv run python src/train.py experiment=cifar_densenet trainer.max_epochs=50
```

### 3. å¿«é€Ÿè°ƒè¯•

```bash
# è°ƒè¯•æ¨¡å¼ (CPU, fast_dev_run, æ— æ—¥å¿—)
make debug

# é™åˆ¶æ­¥æ•°è°ƒè¯•
make debug-limit
```

### 4. è¯„ä¼°æ¨¡å‹

```bash
make eval CKPT=/path/to/checkpoint.ckpt
```

### 5. é¢„æµ‹/æ¨ç†

```bash
make predict CKPT=/path/to/checkpoint.ckpt INPUT=/path/to/images
```

### 6. è¶…å‚æ•°æœç´¢

```bash
make hparams-cifar   # CIFAR-10 è¶…å‚æœç´¢
make hparams-mnist   # MNIST è¶…å‚æœç´¢
```

## Makefile å‘½ä»¤

è¿è¡Œ `make help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤ï¼š

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `make install` | å®‰è£…ä¾èµ–å¹¶åˆå§‹åŒ– DVC |
| `make train` | é»˜è®¤è®­ç»ƒ |
| `make train-exp EXP=xxx` | æŒ‡å®šå®éªŒé…ç½®è®­ç»ƒ |
| `make debug` | è°ƒè¯•æ¨¡å¼ |
| `make eval CKPT=xxx` | è¯„ä¼°æ¨¡å‹ |
| `make predict CKPT=xxx INPUT=xxx` | é¢„æµ‹/æ¨ç† |
| `make hparams-cifar` | CIFAR-10 è¶…å‚æœç´¢ |
| `make lint` | ä»£ç æ£€æŸ¥ä¸æ ¼å¼åŒ– |
| `make tb` | å¯åŠ¨ TensorBoard |
| `make clean` | æ¸…ç†ç¼“å­˜æ–‡ä»¶ |

## é…ç½®ç³»ç»Ÿ

### é…ç½®ç»„

| é…ç½®ç»„ | è¯´æ˜ | å¯é€‰å€¼ |
|--------|------|--------|
| `data` | æ•°æ®é›† | `cifar10`, `mnist` |
| `model` | æ¨¡å‹ | `cifar_resnet`, `cifar_densenet`, `cifar_googlenet`, `cifar_resnet_preact`, `mnist_cnn` |
| `debug` | è°ƒè¯• | `default`, `limit`, `profiler` |
| `experiment` | å®éªŒ | `cifar_resnet`, `cifar_densenet`, `cifar_googlenet`, `cifar_resnet_preact`, `mnist_lr_search` |

> **æ³¨æ„**: `callbacks`ã€`logger`ã€`trainer`ã€`paths`ã€`hydra` å·²æ•´åˆåˆ° `_base.yaml`ï¼Œé€šå¸¸æ— éœ€å•ç‹¬ä¿®æ”¹ã€‚å¦‚éœ€è°ƒæ•´å¯ç›´æ¥åœ¨å‘½ä»¤è¡Œè¦†ç›–ï¼Œå¦‚ `trainer.max_epochs=200`ã€‚

### é…ç½®è¦†ç›–ç¤ºä¾‹

```bash
# æŸ¥çœ‹å®Œæ•´é…ç½®
uv run python src/train.py --cfg job

# è¦†ç›–å•ä¸ªå‚æ•°
uv run python src/train.py trainer.max_epochs=200 data.batch_size=128

# ä½¿ç”¨ GPU è®­ç»ƒï¼ˆè¦†ç›–é»˜è®¤ autoï¼‰
uv run python src/train.py trainer.accelerator=gpu trainer.devices=1

# å¤š GPU åˆ†å¸ƒå¼è®­ç»ƒ
uv run python src/train.py trainer.accelerator=gpu trainer.devices=auto trainer.strategy=ddp

# ç¦ç”¨æ—¥å¿—ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
uv run python src/train.py logger=null

# ç¦ç”¨å›è°ƒ
uv run python src/train.py callbacks=null
```

## æ·»åŠ æ–°å®éªŒ

1. **åˆ›å»ºæ¨¡å‹é…ç½®** `configs/model/your_model.yaml`:
   ```yaml
   _target_: src.models.your_module.YourModule
   # æ¨¡å‹å‚æ•°...
   ```

2. **åˆ›å»ºå®éªŒé…ç½®** `configs/experiment/your_exp.yaml`:
   ```yaml
   # @package _global_
   defaults:
     - override /data: cifar10
     - override /model: your_model
   
   tags: ["your_exp"]
   trainer:
     max_epochs: 100
   ```

3. **è¿è¡Œå®éªŒ**:
   ```bash
   uv run python src/train.py experiment=your_exp
   ```

## æ•°æ®ç®¡ç† (DVC)

```bash
# è·Ÿè¸ªæ•°æ®
dvc add data/your_dataset
git add data/your_dataset.dvc .gitignore
git commit -m "Add dataset"

# æ¨é€åˆ°è¿œç¨‹å­˜å‚¨
dvc remote add -d myremote s3://mybucket/dvcstore
dvc push

# æ‹‰å–æ•°æ®
dvc pull
```

## ç›®å½•è¯´æ˜

| ç›®å½• | è¯´æ˜ |
|------|------|
| `logs/runs/` | è®­ç»ƒæ—¥å¿—å’Œ checkpoint |
| `logs/multiruns/` | è¶…å‚æœç´¢æ—¥å¿— |
| `saved_models/` | æ‰‹åŠ¨ä¿å­˜çš„æ¨¡å‹ |
| `data/` | æ•°æ®é›†å­˜å‚¨ |

## License

MIT
